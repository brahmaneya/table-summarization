%!TEX root = TableSummarization.tex

\section{Related Work}\label{sec:related}

There has been work on finding cubes to browse in OLAP systems~\cite{Sarawagi:2001:UMA:767141.767148, Sarawagi00user-adaptiveexploration, Sarawagi98discovery-drivenexploration}. This work, along with other existing work~\cite{Mampaey:2011:TMI:2020408.2020499} focuses on finding values that occur more often or less often that expected from a max-entropy distribution. The work does not guarantee good coverage of the table, since it rates infrequently occurring sets of values as highly as frequently occurring ones. Some other data exploration work~\cite{sellam:meet} focuses on finding attribute values that divide the database in equal sized parts, while we focus on values that occur as frequently as possible. 

There is work on constructing `explanation tables', which are sets of rules that co-occur with a given binary attribute of the table~\cite{DBLP:journals/pvldb/GebalyAGKS14}. This work again focuses on displaying rules that will cause the resulting max entropy distribution to best approximate the actual distribution of values. A few vision papers~\cite{data-deluge, cetintemel2013query} suggest frameworks for building interactive data exploration systems. Some of these ideas, like maintaining user profiles, could be integrated into a smart drill down system. Reference~\cite{DBLP:conf/edbt/CandanCQS09} proposes an extension to OLAP drill-down that takes visualization real estate into account, by clustering attribute values. But it focuses on expanding a single column at a time, and relies on a given value hierarchy for clustering.

Some related work~\cite{DBLP:journals/debu/GolabKS11, Golab:2008:GNT:1453856.1453900} focuses on finding minimum sized Tableaux that provide improved support and confidence for conditional functional dependencies. There has also been work~\cite{Bu:2005:MSH:1083592.1083644, Lakshmanan:2002:GMA:1287369.1287435, DBLP:conf/kdd/XiangJFD08, Geerts04tilingdatabases} on finding hyper-rectangle based covers for tables. In both these cases, the emphasis is on completely covering or 
summarizing the table, suffering from the same problems as traditional drill down in that the user may be presented with
too many results. The techniques in the former case may end up picking rare ``patterns'' if they have high confidence, and in the latter case do not scale well to a large number of attributes (in their case, $\geq 4$). 

Several existing papers also deal with the problem of frequent itemset mining~\cite{apriori, 1411744, Han:2000:MFP:342009.335372}. Vanilla frequent itemset mining is not directly applicable to our problem because the flexible user-specified objective function emphasizes coverage of the table rather than simply frequent itemsets.  However, we do leverage ideas from the a-priori algorithm~\cite{apriori} as applicable. Several extensions have been proposed to the a-priori algorithm, including those for dealing with numerical attributes~\cite{Srikant:1996:MQA:233269.233311, Miller:1997:ARO:253260.253361}. We can potentially use these ideas to improve handing of numerical attributes in our work. Unlike our paper, there has been no work on dynamically maintaining samples for interaction in the frequent itemset literature, since frequent itemset mining is a one-shot problem.

% All the existing works solve a fixed optimization problem, whereas  we focus on finding an optimal summary for a flexible user-specified weighting function.

We use sampling to find approximate estimates of rule counts. Various other database systems~\cite{Acharya:1999:AAQ:304182.304581, Agarwal:2013:BQB:2465351.2465355} use samples to find approximate results to SQL aggregation queries. These systems create samples in advance and only update them when the database changes. In contrast, we keep updating our samples on the fly, as the user interacts with our system. There is work on using weighted sampling~\cite{6691587} to create samples favouring data that is of interest to a user, based on the user's history. In contrast, we create samples at run time in response to the user's commands.

