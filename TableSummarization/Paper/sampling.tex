%!TEX root = smartDrillDownICDE.tex

\subsection{Dynamic Sampling for Large Tables}\label{sec:sampling}

\papertext{
BRS makes multiple passes over the table in order to determine the best set of rules to display. This can be slow when the table is too large to fit in main memory. We can reduce the response time of smart drill down by running BRS on a sample of the table instead, trading off accuracy of our rules for performance. If we had obtained a sample $s$ by selecting each table tuple with probability $p$, and run BRS on $s$, then we multiply the count of each rule found by BRS, by $\frac{1}{p}$ to estimate its count over the full table.

In Section~\ref{sec:sampling_algorithms}, we describe the problem of optimally allocating memory to different samples. We show that the problem is NP-Hard, and describe an approximate solution. In Section~\ref{sec:sample-handler}, we describe a component of the system called the {\em SampleHandler}, which is responsible for creating and maintaining multiple samples of different parts of the table in memory, and creating temporary samples for BRS to process. Detailed descriptions of the sampling problem and the SampleHandler are in the technical report. The technical report also contains some additional optimizations, and ways to set the minimum sample size.

\subsubsection{Deciding what to sample}\label{sec:sampling_algorithms}
We are given a memory capacity $M$, and a minimum sample size $minSS$, both specified by the user. $minSS$ is the minimum number of tuples on which we are allowed to run BRS, without accessing the hard disk. A higher value of $minSS$ increases both accuracy and computation cost of our system.

At any point, we have a tree $U$ of rules displayed to the user. Initially, the tree consists of a single node corresponding to the empty rule. When the user drills down on a rule $r$, the sub-rules of $r$ obtained by running BRS are added as children of node $r$. 
Our system maintains multiple samples in memory, with one sample per rule in $U$. Specifically, for each rule $r \in U$, we choose an integer $n_r$, and create a sample $s_r$ consisting of $n_r$ uniformly randomly chosen tuples covered by $r$ from the table. Because of the memory constraint, we must have $\sum_{r\in U} n_r \leq M$. 

When a user attempts to drill down on $r$, the SampleHandler takes all $n_r$ tuples from $s_r$, and also tuples covered by $r$ from samples $s_{r'}$ for all $r' \in U$ that are sub-rules of $r$. If the total number of such tuples is $\geq minSS$, then we run BRS on that set of tuples to perform the drill down. Note that this set of tuples forms a uniformly random sample of tuples covered by $r$. If not, then we need to access the hard disk to obtain more tuples covered by $r$.

Leaves of tree $U$ correspond to rules that may be drilled down on next. We assume there is a probability distribution over leaves, which assigns a probability that each leaf may be drilled down on next. This can be a uniform distribution, or a machine learned distribution using past user data. We aim to set sample sizes $n_r$ so as to maximize the probability that the next drill down can be performed without accessing the hard disk. 

If $r'$ is a sub-rule of $r$, and covers $x$ times as many rules as $r$, then it means that when drilling down on $r$, $s_{r'}$ can contribute around $\frac{n_{r'}}{x}$ tuples to the sample for $r$. We denote the ratio of selectivities $x$ by $S(r',r)$. $S(r',r)$ is defined to be $0$ if $r'$ is not a sub-rule of $r$. If $r$ is to be drilled down on next, the total number of sample tuples we will have for $r$ from all existing samples is given by $ess(r) = \sum_{r'\in U} S(r', r)n_{r'}$. We can drill down on $r$ without accessing hard disk, if $ess(r) \geq minSS$. We now formally define our problem: 
\begin{problem}\label{prob:sample-sizes}
Given a tree of rules $U$ with leaves $L$, a probability distribution $p$ over $L$, an integer $M$, and selectivity ratio $S(r_1, r_2)$ for each $r_1, r_2 \in U$, 
choose an integer $n_r \geq 0$ for each $r \in U$ so as to $\textrm{maximize}$ :
$$\sum_{r^{\prime} \in L} p_{r^{\prime}}I_{[ess(r^{\prime}) \geq minSS]}$$
where the $I$'s are indicator variables, subject to :
$\sum_{r \in U} n_r \leq M$
\end{problem}
Problem~\ref{prob:sample-sizes} is non-linear and non-convex because of the indicator variables. 
%If the tree $U$ is not too big, then it might be feasible to use an exponential algorithm to solve the problem. 
We can show that Problem~\ref{prob:sample-sizes} is {\sc NP-Hard} using a reduction from the knapsack problem. 
\begin{lemma}\label{lemma:sampling-hardness}
Problem~\ref{prob:sample-sizes} is {\sc NP-Hard}.
\end{lemma}
\begin{proof}(Sketch)
Suppose we are given an instance of the knapsack problem with $m$ objects, with the $i^{th}$ object having weight $w_i$ and value $v_i$. We are also given a weight limit $W$, and our objective is to choose a set of objects that maximizes value and has total weight $< W$. We will reduce this instance to an instance of Problem~\ref{prob:sample-sizes}.

We first scale the $w_i$s and $W$ such that all $w_i$s are $< 1$. For Problem~\ref{prob:sample-sizes}, we set $M$ to $(m + W) \times minSS$. Tree $U$ has $m$ special nodes $r_1, r_2, ... r_m$, and each $r_i$ has two leaf children $r_{i,1}, r_{i,2}$. All other leaves have expansion probability $0$. 
The $S$ values are such that $\forall i \in \left\lbrace 1, 2, ..m\right\rbrace, j \in \left\lbrace 1, 2 \right\rbrace : (S(x, r_{i,j}) \neq 0 \Rightarrow x = r_{i,j} || x = r_i)$. In reality, the $S$ values cannot be exactly zero, but can be made small enough for all practical purposes. Thus, $\forall 1 \leq i \leq m, j \in \left\lbrace 1,2 \right\rbrace : ess(r_{i,j}) = n_{r_{i,j}} + n_{r_i}S(r_i, r_{i,j})$. In addition, $S(r_i, r_{i,1}) = 1$, and $S(r_i, r_{i,2}) = 1 - w_i$. Finally, $\forall i : p_{r_{i,1}} = \frac{2}{2m+1}$ and $p_{r_{i,2}} = \frac{v_i}{(2m+1)\sum_{j=1}^{m}v_i}$. So in any optimal solution, $\forall i : ess(r_{i,1}) = minSS$, and we've to decide which $i$'s also have $ess(r_{i,2}) = minSS$. Having $ess(r_{i,2}) = minSS$ requires consuming $w_i \times minSS$ extra memory and gives an extra $\frac{v_i}{(2m+1)(\sum_{j=1}^{m}v_j)}$ probability value. Thus, having $ess(r_{i,2}) = minSS$ is equivalent to picking object $i$ from the knapsack problem. Solving Problem~\ref{prob:sample-sizes} with the above $U$, $S$, $p$ and picking the set of $i$'s for which $ess(r_{i,2}) = minSS$ gives a solution to the instance of the knapsack problem. 
\end{proof}
\vspace{-10pt}
\noindent A more detailed proof sketch is given in the technical report.}

\techreporttext{
Our greedy algorithm needs to make multiple passes over the entire table in order to find counts of rules. These passes can be expensive if the table is large and the table does not fit in main memory. If we want exact counts for rules, we have no choice but to read the entire table. 

But if we are willing to accept approximate counts rather than exact counts, we can speed up our algorithm by loading a sample of the table into main memory, finding rule counts on the sample, and scaling up the count. Thankfully since our goal is to find a representative coverage of the table, if we miss out on a few rare tuples, it does not hurt us. If we had obtained the sample by sampling each tuple with probability $p$, then we must scale up the sample count of each rule by $\frac{1}{p}$ to get an estimate of its count over the full table. 

Thus, we use sampling to trade-off a small amount of accuracy for a faster response time. We now describe our sampling schemes for improving the running time of our algorithm on tables that are too large to fit in main memory. 

We describe our technique to efficiently allocate memory to different samples, so as to maximize the probability that we can respond to the next user operation without accessing the hard disk in Section~\ref{sec:sampling_algorithms}. 
Then, in Section~\ref{sec:sample-handler}, we describe a component of our system, called the {\em SampleHandler}, which is responsible for creating and maintaining samples of the table in memory, subject to user specified memory constraints. The SampleHandler maintains multiple samples corresponding to different parts of the table, which can be used depending on which rule the user decides to expand next. Finally, we mention some additional optimizations we can make, and
describe how we can set the minimum sample size required from the SampleHandler.

\subsubsection{Algorithms for deciding what to sample}\label{sec:sampling_algorithms}

We are given a memory capacity or budget $M$, and a minimum sample size $minSS$ (both specified by the user). \mrj{$M$ can simply be set to the actual available memory, while $minSS$ can easily be computed as a function of the desired estimation error.}
The parameter $minSS$ is the minimum number of sample tuples needed
such that we can use the sample in memory 
instead of having to resort to the entire table stored
on hard disk. 
This parameter determines how accurate our count estimates will be, and also
how quickly we can return results to the user. \mrj{The count estimate error is proportional to $\sqrt{\frac{1}{minSS}}$ while runtime is proportional to $minSS$.}

We now consider the following problem: say we currently have no
samples in memory (we describe the scenario where there are already 
some samples in Section~\ref{sec:sample-handler}), and say the user is currently viewing some rules; how do we
materialize the ``best possible'' samples in memory that fit within the capacity $M$,
such that we can respond to as many user interactions as possible using the stored samples,
without having to resort to retrieving the entire table.
That is, we want to maximize the probability that the next user interaction
can be answered using the existing samples, without reading from the hard disk. 
We leverage techniques from approximation algorithms and optimization theory, formalized
below.


\stitle{Tree of Rules.}
At any stage, we have a tree $U$ of rules displayed to the user, 
with each node of the tree corresponding to a displayed rule. 
In the rest of this section, we will refer to nodes in $U$ and rules interchangeably.
The tree is formed as follows: The root of the tree corresponds to the trivial rule. 
And suppose the user expands a node with rule $r$, resulting in rules $r_1, r_2, .. r_k$ being displayed. 
Then we add children nodes to the expanded node, corresponding to rules $r_1, r_2, .. r_k$, and so on.

Even though the rules displayed to the user can be considered a tree, 
multiple nodes of the tree may correspond to the same rule. 
For example, $(a, b)$ may be a child of both $(\star, b)$ and $(a, \star)$.
Thus, even though the structure displayed to the user is a tree, 
the set of rules displayed forms a partially ordered set (poset) using the sub-rule ordering. 
However, for the purposes of this section, we focus on the tree representation.


Internal nodes of the tree $U$ are ones that have been expanded (drilled down on), 
while the leaves are nodes that have not been expanded. 
Let $L$ be the set of leaves. 
Each leaf is something that the user can potentially expand in the next step, and thus we would like to have pre-fetched samples for rules corresponding to leaf nodes.

\stitle{Probability Distribution.} 
We assume that we have a probability distribution over leaves, which assigns a probability that each leaf will be the next one to be expanded. In the absence of additional data, we can assume a uniform probability distribution. That is, we can assume that every leaf is equally likely to be expanded next. If we have data on past user behaviour available, we can use Machine Learning on node features such as `node depth in tree', `weight of node rule' and `distance from last expanded node' to get a better probability estimate of each node being expanded next. 


% When the SamplerHandler uses \textbf{Create} for a rule $r$, it needs to make a pass through the entire table, as well as potentially shrink some existing samples to free up memory. Since making a pass over the the table from the hard disk is usually a bottleneck, it can also do things like creating samples for rules other than $r$, and augmenting existing samples, in the same pass. Hence, we assume that in a \textbf{Create} phase, the SampleHandler not only creates one new sample for $r$, but also potentially creates other new samples, or resizes existing samples. For each displayed rule $r^{\prime}$, it may create a new sample for $r^{\prime}$ in the same pass through the table. Based on the current leaves and their expansion probabilities, it finds an optimal set of sizes of samples to create for each displayed rule. More specifically, for every displayed rule $r^{\prime}$, it determines an integer $n_{r^{\prime}}$, and then creates a fresh sample $s_{r^{\prime}}$ with $f_{s_{r^{\prime}}} = r^{\prime}$ and $|T_{s_{r^{\prime}}}| = n_{r^{\prime}}$ while making its pass through the table. 

\stitle{Sampling Strategy.} The sampling strategy we adopt involves storing, 
for every displayed rule $r'$, a sample of $r'$ of size $n_{r'}$, i.e., 
containing $n_{r'}$ randomly chosen tuples $\in r'$.
Note that we may choose to not store a sample for some rules, in which case $n_{r'}$
will be zero for those rules. 
We need to pick the $n_{r^{\prime}}$ values so as to maximize the probability that the next user drill down can be satisfied using samples available in memory. 
As it turns out, picking a sample for some rules can help not just that rule, but
also all of its sub-rules, all the while preserving uniform randomness of samples. We formalize this notion next.


\stitle{Selectivity.} 
Let the `selectivity' of a rule be the fraction of tuples in $T$ that are covered by the rule. 
For each pair of rules $r_1, r_2 \in U$ such that $r_1$ is a sub-rule of $r_2$, we can estimate the ratio of selectivities of $r_1$ and $r_2$ using existing samples. We denote this quantity as $S(r_1, r_2)$. 
We define $S(r_1, r_2)$ to be $0$ if $r_1$ is not a sub-rule of $r_2$. 
If the same rule occurs in multiple nodes $r_1$, $r_2$ of the tree, then $S(r_1, r_2)$ is naturally $1$. 
Essentially, $S(r_1, r_2)$ denotes how much $r_1$'s sample helps $r_2$. 
If $r_1$ is a strict super-rule of $r_2$, then $S$ will be $0$ since using a sample of $r_1$
for $r_2$ will lead to bias.

Then, if we have an $n_r$ sized uniformly random sample of tuples covered by $r$ for each $r \in U$, the expected number of tuples covered by $r^{\prime} \in L$ is denoted as $ess(r')$ (for `effective sample size'), as below: 
\begin{equation} \label{def:ess}
ess(r^{\prime}) = \sum_{r \in U} S(r, r^{\prime})n_r
\end{equation}
Basically, $ess(r')$ captures how much of an unbiased sample of $r'$ can be retrieved using all the samples for the rules in $U$.
If $ess(r^{\prime}) \geq minSS$, then if the user expands $r^{\prime}$, we do not need to make another 
pass through the table.

We wish to set the sample size $n_r$ of each rule so as to maximize the probability that we can respond to the next user expansion without making another pass. We now formally define our problem below:
\begin{problem}\label{prob:sample-sizes}
Given a tree of rules $U$ with leaves $L$, a probability distribution $p$ over $L$, an integer $M$, and selectivity ratio $S(r_1, r_2)$ for each $r_1, r_2 \in U$, 
choose an integer $n_r \geq 0$ for each $r \in U$ so as to $\textrm{maximize}$ :
$$\sum_{r^{\prime} \in L} p_{r^{\prime}}I_{[ess(r^{\prime}) \geq minSS]}$$
where the $I$'s are indicator variables, subject to :
$\sum_{r \in U} n_r \leq M$
\end{problem}
Problem~\ref{prob:sample-sizes} is non-linear and non-convex because of the indicator variables. 
%If the tree $U$ is not too big, then it might be feasible to use an exponential algorithm to solve the problem. 
We can show that Problem~\ref{prob:sample-sizes} is {\sc NP-Hard} using a reduction from the knapsack problem. 
\begin{lemma}\label{lemma:sampling-hardness}
Problem~\ref{prob:sample-sizes} is {\sc NP-Hard}.
\end{lemma}
\begin{proof}(Sketch)
Suppose we are given an instance of the knapsack problem with $m$ objects, with the $i^{th}$ object having weight $w_i$ and value $v_i$. We are also given a weight limit $W$, and our objective is to choose a set of objects that maximizes value and has total weight $< W$. We will reduce this instance to an instance of Problem~\ref{prob:sample-sizes}.

We first scale the $w_i$s and $W$ such that all $w_i$s are $< 1$, without effectively changing the problem. For Problem~\ref{prob:sample-sizes}, we set $M$ to $(m + W) \times minSS$. Tree $U$ has $m$ special nodes $r_1, r_2, ... r_m$, and each $r_i$ has two children $r_{i,1}, r_{i,2}$. These $2m$ children are all leaves, and all leaves other than these have expansion probability $0$. 
The $S$ values are such that $\forall i \in \left\lbrace 1, 2, ..m\right\rbrace, j \in \left\lbrace 1, 2 \right\rbrace : (S(x, r_{i,j}) \neq 0 \Rightarrow x = r_{i,j} || x = r_i)$. In reality, the $S$ values cannot be exactly zero when the first argument is the trivial rule, but we can make it small enough such that any optimal solution will set $n_r = 0$ when $r$ is not a special node or its child. Therefore, each leaf $r_{i,j}$ gets tuples either from its own sample, or the sample of its parent, and from nowhere else. Thus, $ess(r_{i,j}) = n_{r_{i,j}} + n_{r_i}S(r_i, r_{i,j}) \forall 1 \leq i \leq m, j \in \left\lbrace 1,2 \right\rbrace$. In addition, $S(r_i, r_{i,1}) = 1$ (again, it cannot be exactly $1$, but can be brought arbitrarily close to $1$), and $S(r_i, r_{i,2}) = 1 - w_i$. Finally, for each i, $p_{r_{i,1}} = \frac{2}{2m+1}$ and $p_{r_{i,2}} = \frac{v_i}{(2m+1)\sum_{j=1}^{m}v_i}$. Thus, each individual $p_{r_{i,1}}$ value is higher than all $p_{r_{i,2}}$ values combined, and $M$ is high enough to cover all $r_{i,1}$. As a result, in any optimal solution, $ess(r_{i,1})$ must be equal to $minSS$ for all $i$, and we're left to decide which $i$'s should also have $ess(r_{i,2}) = minSS$. For all $i$, we must have either $n_{r_i} = n_{r_{i,2}} = 0 \land n_{r_{i,1}} = minSS$ (iff $ess(r_{i,2}) < minSS$) or $n_{r_i} = minSS \land n_{r_{i,1}} = 0 \land n_{r_{i,2}} = minSS (1 - S(r_i, r_{i,2})) = minSS \times w_i$ (iff $ess(r_{i,2}) = minSS$). The latter option consumes $w_i \times minSS$ extra memory and gives an extra $\frac{v_i}{(2m+1)(\sum_{j=1}^{m}v_j)}$ probability value. Thus, having $ess(r_{i,2}) = minSS$ is equivalent to picking object $i$ from the knapsack problem (as it consumes additional memory $\propto w_i$ and gives additional probability value $\propto v_i$). Moreover, the additional memory available (on top of the $m \times minSS$ required to cover all $r_{i,1}$s) is $W\times minSS$. Hence, solving Problem~\ref{prob:sample-sizes} with the above $U$, $S$, $p$ and picking the set of $i$'s for which $ess(r_{i,2}) = minSS$ gives a solution to the instance of the knapsack problem. 
\end{proof}
}

\stitle{Approximate DP Solution.} Even though the problem as stated is {\sc NP-Hard}, with an additional simplifying assumption, we can make the problem approximately solvable using a Dynamic Programming algorithm. The assumption is: for each $r \in L$, we assume that its $ess$ can get sample tuples only from samples obtained for itself and its immediate parent. That is, we set $S(r_1, r_2)$ to be zero if $r_1 \neq r_2$ and $r_2$ is not a child of $r_1$. This is similar to what we had for tree $U$ in our proof of Lemma~\ref{lemma:sampling-hardness}. $ess(r)$ now becomes $ess(r^{\prime}) = n_{r^{\prime}} + n_rS(r, r^{\prime})$ where $r$ is the parent of $r^{\prime}$.

\papertext{We present the idea behind the approximate solution below. A more detailed description can be found in the technical report. The solution consists of two main steps:
\squishlist
\item \textbf{Locally Optimal Solutions :} For each rule $r_0 \in U \setminus L$, let $M_{r_0}$ be the set consisting of $r_0$ and its leaf children. We consider the number of tuples assigned to members of $M_{r_0}$. Each such assignment of numbers has a `cost' equal to total number of tuples assigned, and `value' equal to sum of probabilities of $M_{r_0}$ members with $ess > minSS$. We consider all `locally optimal' assignments, where probability value cannot be increased without increasing the cost.
\item \textbf{Combining Solutions :} Then, we use dynamic programming to pick one optimal solution per $r_0$ so as to get maximum probability value with the given cost constraint. We discretize costs, say to have granularity $100$. Let $M_{0}, M_{1}, ... M_{D}$ be the sets for which we have found locally optimal solutions. We make $D$ iterations in all, where in the $i^{th}$ iteration, we try different locally optimal solutions for $M_i$ and use it to update the maximum attainable value for each cost. 
\squishend
}

\techreporttext{
Now consider a rule in $r_0 \in U \setminus L$ along with all its children. Let $M_{r_0}$ denote the set containing $r_0$ and all its leaf children. Then, by our simplification, the number of tuples $n_{r^{\prime}}$ for any rule in $r^{\prime} \in M_{r_0}$ only affects the $ess$ value of rules in $M_{r_0}$. This allows us to effectively split the problem into multiple subproblems,  with one subproblem per $M_{r_0}$. Thus, for each non-leaf rule $r_0$ and all its children, we compute all `locally optimal' assignments of $n_r \mid r \in M_{r_0}$. Locally optimal means that we cannot get a higher value of `probability value' $\sum_{r \in M_{r_0}} p_rI_{ess(r) \geq minSS}$ for the same `sampling cost' $\sum_{r\in M_{r_0}} n_r$. Then, we can use dynamic programming to combine the locally optimal solutions of different $M_{r_0}$s. We describe both these steps in detail below:

Let $r_0 \in U \setminus L$. Let $d$ be the number of leaf children of $r_0$. Let the children be $r_1, r_2, ... r_d$. For any child $r_i$, $n_{r_i}$ only contributes to its own $ess$, whereas $n_{r_0}$ contributes to the $ess$ of all children $r_1, ... r_d$. Given a value of $n_{r_0}$, in a locally optimal solution, each child $r_i$ must satisfy:
\squishlist
\item If $n_{r_0}S(r_0, r_i) \geq minSS$, then $n_{r_i} = 0$ because otherwise, decreasing $n_{r_i}$ to $0$ would lower its sampling cost without improving its probability score. 
\item If $n_{r_0}S(r_0, r_i) < minSS$, then either $n_{r_i} = 0$ or $n_{r_i} = minSS - n_{r_0}S(r_0, r_i)$. This is because if $n_{r_i}$ is between $0$ and $minSS - n_{r_0}S(r_0, r_i)$, then we can decrease it to $0$, and if it is $> minSS - n_{r_0}S(r_0, r_i)$, then we can decrease it to $minSS - n_{r_0}S(r_0, r_i)$. Both these decreases would decrease sampling cost without affecting probability score. 
\squishend
Thus, there are three kinds of children $r_i$: Those with $ess \geq minSS$ but $n_{r_i} = 0$, those with $ess < minSS$ and $n_{r_i} = 0$, and those with $ess = minSS$ and $n_{r_i} = minSS - n_{r_0}S(r_0, r_i)$. There are $3^d$ ways to assign each child to one of these categories, and each of those potentially gives us one locally optimal solution. Consider any such locally optimal solution $e$. For $e$ let children $r_{i_1}, r_{i_2}, ... r_{i_m}$ be in the first category, $r_{i_{m+1}}, .. r_{i_M}$ be in the second category, and $r_{i_{M+1}}, .. r_{i_d}$ in the third.  Then the `probability value' of solution $e$ is given by : 
$P(e) = \sum_{j = 1}^{i_M}p_{j}$,
and its `Sampling Cost' is
$$S(e) = \frac{minSS}{S(r_0, r_{i_m})} + \sum_{j=i_m+1}^{i_M} minSS - \frac{minSS}{S(r_0, r_{i_j})}$$
Thus, there are at most $3^d$ locally optimal solutions; $d$ is usually small (it is at most $k$, the size of the rule-list we create on every user click), even when the rule tree $U$ itself is big, and so we can enumerate all $3^d$ locally optimal solutions and find their sampling cost and probability scores.

Then next step is to combine the solutions using dynamic programming. Let the $M$ sets be called $M_0, M_1, ... M_D$. Let our possible sample sizes range from $0$ to $\mathcal{S}$. The number of sample sizes can be pretty large ($\mathcal{S}$), but we can make it smaller by discretizing the sample sizes, say to have granularity $100$. Then we create a $D \times \mathcal{S}$ array $A$. The value $A\left[i\right]\left[j\right]$ contains the best probability score we can get from $M_0, M_1, ... M_i$ with total sample size at most $j$. We can populate $A\left[0\right]\left[j\right] \forall j$ using the locally optimal solutions for $M_0$. Let $E_{i+1}$ denote the set of locally optimal solutions for $M_{i+1}$. Then we have,
$$A\left[i+1\right] \left[j \right] = \textrm{max} (A\left[i\right]\left[j\right], \textrm{max}_{e \in E_{i+1}}(A\left[i\right]\left[j-S(e)\right] + P(e)))$$
This can be solved using dynamic programming, in $O(D\mathcal{S}3^d)$ time. 
}

\techreporttext{
\subsubsection{Alternative Convex-Optimization based solution}
We noted earlier that Problem~\ref{prob:sample-sizes} is NP-Hard, but can be approximately solved with an additional simplifying assumption regarding the $S(r_1, r_2)$ values. Instead of making this simplification, we can make the problem convex (and hence tractable) with two different simplifications. The first simplification is, we modify our objective function to use hinge-loss instead of a step function. That is, our new objective function to maximise is $$\sum_{r^{\prime} \in L} p_{r^{\prime}}\textrm{min}(1, \frac{ess(r^{\prime})}{minSS} $$
Here we assume that it is acceptable to run our algorithm on samples smaller than $minSS$,  though we still prefer bigger sample sizes upto $minSS$. The other simplification we make is assuming that the sample sizes $n_r$ are real numbers instead of integers. After obtaining our optimal sample sizes, we can round them up to get integer sample sizes. This will increase the memory usage by at most $|U|$, the number of nodes in displayed tree. $|U|$ is usually negligible compared to the memory capacity $M$, or $minSS$.

In addition, in order to express our problem as a convex minimization problem, we negate the objective function and aim to minimize it (which is equivalent to maximizing the original objective function). Thus, our new optimization problem becomes
\begin{problem}\label{prob:sample-sizes-hinge-loss}
Given a tree of rules $U$ with leaves $L$, a probability distribution $p$ over $L$, an integer $M$, and selectivity ratio $S(r_1, r_2)$ for each $r_1, r_2 \in U$, 
choose a real number $n_r \geq 0$ for each $r \in U$ so as to $\textrm{minimize}$ :
$$\sum_{r^{\prime} \in L} p_{r^{\prime}}\textrm{max}(-1, -\frac{ess(r^{\prime})}{minSS} $$
subject to :
$$\sum_{r \in U} n_r \leq M$$
\end{problem}
The constraint is linear in the $n_r$ variables, and hence convex. Each $ess$ value is a linear function of the $n_r$s, which makes $-\frac{ess(r^{\prime})}{minSS}$ convex. The constant function $-1$ is convex as well. Since the maximum of two convex functions is convex, Problem~\ref{prob:sample-sizes-hinge-loss} is a convex minimization problem, which means that its local optimum is also its global optimum. Thus, we can initialize all $n_r$s to $0$ and then use stochastic gradient descent (or any other local optimization technique) to find their optimum values. 

The main weakness of this approach is that the hinge-loss objective rewards values of $ess < minSS$, which may lead us to all leaves having large $ess$ values that are nonetheless less than $minSS$, and thus gives lower quality count estimates than required by the user.


\subsubsection{Additional optimizations}
There are some additional minor optimizations we can make to reduce the memory cost per sample, allowing us to store more and bigger samples. 
Suppose we have a sample $s$, and say its filter rule $f_s$ has value $v$ in column $c$. Then we know that each tuple $t$ in $T_s$ must also have value $v$ in column $c$, since it is covered by $f_s$. So we do not need to explicitly store the column $c$ value of any tuple in $T_s$. We only need to store the tuple values of columns that have a $\star$ value in $f_s$.
In addition, we may have a tuple occur in multiple samples. Instead of storing the entire tuple repeatedly, we could create a dictionary of common tuples, and only store a pointer to the tuple's dictionary entry in $T_s$. 


\subsubsection{Setting $minSS$}
Suppose a rule $r$ covers $x$ fraction of the tuples of $T$ i.e. $x|T|$ tuples. Say we have a uniform random sample $s$ of $T$. The samples has size $|T_s|$, and let $X_{r,s}$ be the random variable denoting the number of tuples of $T_s$ covered by $r$. Then $E\left[ X_{r,s} \right] = x|T_s|$, and $\text{Dev}(X_{r,s}) \approx \sqrt{|T_s|x(1-x)}$. In order to get a good estimate of $x$ (and hence of Count$(r) = x|T|$), we want $E\left[X_{r,s}\right] >> \text{Dev}(X_{r,s})$. That is, $x|T_s| >> \sqrt{|T_s|x(1-x)} \Leftrightarrow \frac{x|T_s|}{1-x} >> 1$. 

We want to set the parameter minSS such that we get good count estimates for rules when using a sample of size $|T_s| = minSS$. If a rule displayed in our summary has covers $x$ fraction of the tuples, we want minSS to be at least $\rho\frac{1-x}{x}$, So the value of minSS must be at least $\rho\frac{1-x}{x}$ where $\rho$ is a constant chosen by us based on how accurate we want the count estimate to be. Moreover, since we want good Count estimates for all rules displayed in the summary, we want $minSS >> \rho\frac{1-x}{x}$ where $x$ is the minimum fraction of tuples covered by any of the rules displayed in our summary.

Thus, a reasonable value of minSS can be found by obtaining a bound on $\frac{1-x}{x}$. This is hard to do for arbitrary weighting functions, but we can do it for the Size weighting function (where weight of a rule equals number of non-$\star$ values of the rule). Let $c$ be the column with the fewest distinct values. Say it has $|c|$ values. Then the rule that has the most frequent value of $c$, and $\star$ everywhere else, must have a score of at least $\frac{|T|}{|c|}$. For example, if the table has $10000$ tuples in all, and there is a `Education' column that has 5 possible values, then the most frequent value of Education must occur at least $2000$ times. So the rule with the most frequent value for Education, and $\star$s elsewhere, must have a score of at least $2000$. 

The highest scoring rule can have weight at most $|C|$ (the total number of columns). Since the score of the highest scoring rule is at least $\frac{|T|}{|c|}$, the Count of the highest scoring rule must be at least $\frac{|T|}{|C||c|}$. Thus if minSS is significantly larger than $|C||c|$, then the Count of the first few highest scoring rules should be well-approximated in a sample of size more than minSS. For example, if $|T| = 10000$, $|c| = 5$, $|C| = 10$, then we want $minSS >> 5 \times 10$.
}



\subsubsection{Design of the SampleHandler}\label{sec:sample-handler}
\papertext{
We now briefly describe the design of the {\em SampleHandler}, which given
a certain memory capacity $M$, and a minimum sample size $minSS$,
creates, maintains, retrieves, and removes samples, all in
response to user interactions on the table. A detailed description, with some potential optimizations, can be found in the technical report.  

At all points, the SampleHandler maintains a set of samples in memory. Each sample $s$ is represented as a triple: (a) A `filter' rule $f_s$, (b) a scaling factor $N_s$ and (c) a set $T_s$ of tuples from the table. The set $T_s$ consists of a $\frac{1}{N_s}$ uniformly sampled fraction of tuples covered by $f_s$. The scaling factor $N_s$ is used to translate the count of a rule on the sample into an estimate of the count over the entire table. The sum of $|T_s|$ over all samples $s$ is not allowed to exceed capacity $M$ at any point. 

Whenever the user drills down on a rule $r$, our system calls the SampleHandler with argument $r$, which returns a sample $s$ whose filter value is given by $f_s = r$ and has $|T_s| \geq minSS$. The $T_s$ of the returned sample consists of a uniformly random set of tuples covered by $r$. The SampleHandler also computes $N_s$ when a sample is created. Then we run BRS on sample $s$ to obtain the list of rules to display. The SampleHandler uses one of the mechanisms below to obtain such a sample $s$:

\squishlist
\item \textbf{Find:} If the SampleHandler finds an existing sample $s$ in memory, which has $r$ as its filter rule (i.e. $f_s = r$) and at least $minSS$ tuples ($|T_s| \geq minSS$, then it simply returns sample $s$. 

\item \textbf{Combine:} If \textbf{Find} doesn't work i.e., if the SampleHandler cannot find an existing sample with filter $r$ and $\geq minSS$ tuples, then it looks at all existing samples $s^{\prime}$ such that $f_{s^{\prime}}$ is a sub-rule of $r$. If the set of all tuples that are covered by $r$, from all such $T_{s^{\prime}}$'s combined, exceeds $minSS$ in size, then we can simply treat that set as our sample for rule $r$.

\item \textbf{Create:} If \textbf{Combine} doesn't work either, then the SampleHandler needs to create a new sample $s$ with $f_s = r$ by making a pass through the table.  Since accessing the hard disk is expensive, it also creates samples for rules other than $r$ and augments existing samples in the same pass. It first deletes all existing samples, then uses the algorithm from Section~\ref{sec:sampling_algorithms} to determine how many tuples to sample for each rule, and uses reservoir sampling~\cite{maibdr1983,Vitter:1985:RSR:3147.3165} to create a uniformly random sample of a given size for each rule.
\squishend
}

\techreporttext{
We now describe the design of the {\em SampleHandler}, which given
a certain memory capacity $M$, and a minimum sample size $minSS$,
creates, maintains, retrieves, and removes samples, all in
response to user interactions on the table.
It uses the algorithms from Section~\ref{sec:sampling_algorithms} 
to decide which samples to create, as we will see below.

At all points, the SampleHandler maintains a set of samples in memory. For instance, it may keep a sample of tuples used to expand the first (trivial) rule, and another sample used to expand the rule last clicked on by the user. 
Each sample $s$ is represented as a triple: (a) A `filter' rule $f_s$, (b) a scaling factor $N_s$ and (c) a set $T_s$ of tuples from the table. The set $T_s$ consists of a $\frac{1}{N_s}$ uniformly sampled fraction of tuples covered by $f_s$. The scaling factor $N_s$ is used to translate the count of a rule on the sample into an estimate of the count over the entire table. The sum of $|T_s|$ over all samples $s$ is not allowed to exceed capacity $M$ at any point. 

Whenever the user drills down on a rule $r$, our system calls the SampleHandler with argument $r$, which returns a sample $s$ whose filter value is given by $f_s = r$ and has $|T_s| \geq minSS$. Thus, the $T_s$ of the returned sample consists of a uniformly random set of tuples covered by $r$. The SampleHandler also computes $N_s$ when a sample is created. Then we run BRS on sample $s$ (with a modified weight function in case the user clicked on a $\star$) to obtain the list of rules to display. The counts of the rules on the sample are multiplied by $N_s$ before being displayed, to get estimated counts on the entire table. In addition, since the sample is uniformly random, we can also compute confidence intervals on the estimated count of each displayed rule, although we do not currently display the confidence intervals.

When the SamplerHandler gets called with argument $r$, it needs to find or create a sample with $r$ as the filter rule. At the beginning when it gets called with the empty rule as an argument, there are no samples in memory and it must make a pass through the data to generate a sample. Creating a new sample by making a pass through the table is called \textbf{Create} (further described below). At later stages, when there are potentially multiple samples available, there are multiple mechanisms it could use to return a sample for rule $r$:
\squishlist
\item \textbf{Find:} If the SampleHandler finds an existing sample $s$ in memory, which has $r$ as its filter rule (i.e. $f_s = r$) and at least $minSS$ tuples ($|T_s| \geq minSS$, then it simply returns sample $s$. BRS can then be run on $s$. 

\item \textbf{Combine:} If \textbf{Find} doesn't work i.e., if the SampleHandler cannot find an existing sample with filter $r$ and $\geq minSS$ tuples, then it looks at all existing samples $s^{\prime}$ such that $f_{s^{\prime}}$ is a sub-rule of $r$. If the set of all tuples that are covered by $r$, from all such $T_{s^{\prime}}$'s combined, exceeds $minSS$ in size, then we can simply treat that set as our sample for rule $r$.
We can show that tuples that are covered by $r$, from the combination of $T_{s^{\prime}}$s, follow a uniform distribution. That is, each table tuple $t$ that is covered by $r$ is equally likely to appear in a $T_{s^{\prime}}$. 

Note that the \textbf{Combine} procedure doesn't really require additional memory apart from the temporary memory used by BRS. Since all the tuples in the `new' sample are already present in existing samples, it can give BRS a set of temporary pointers to the tuples, and the memory for the pointers can be freed as soon as the sample has been processed by BRS. In contrast, if we had created a new sample from hard disk, we would maintain the sample even after BRS terminated, and would hence need to use memory from the SampleHandler's capacity $M$.
%TODO: Not sure how clear/necessary this is.  

\item \textbf{Create:} If \textbf{Combine} doesn't work either, then the SampleHandler needs to create a new sample $s$ with $f_s = r$ by making a pass through the table. Making a pass can be expensive for big tables, so we only use \textbf{Create} when \textbf{Find} and \textbf{Combine} cannot be used. We can use reservoir sampling~\cite{maibdr1983,Vitter:1985:RSR:3147.3165} to get a uniformly random sample of given size in a single pass through the table. 

When the SamplerHandler uses \textbf{Create} for a rule $r$, it needs to access the hard disk to make a pass through the entire table. Since accessing the hard disk and making a pass through the entire table is usually a bottleneck, it can also do things like creating samples for rules other than $r$, and augmenting existing samples, in the same pass. Hence, we assume that in a \textbf{Create} phase, the SampleHandler not only creates one new sample for $r$, but also uses the algorithm from Section~\ref{sec:sampling_algorithms} to determine the new optimal allocation of memory $n_r$ for each displayed rule $r$. Then in a single pass, it creates a sample of size $n_r$ for each displayed $r$. 
\squishend
}

\techreporttext{
\smallskip
\noindent \textbf{Pre-fetching:} When the user clicks on rule $r$ (on the rule itself or on a $\star$ in the rule), we need to get a sample, run the BRS, and display a rule-list to the user. If we use \textbf{Find} or \textbf{Combine}, then we can display the rule-list much faster because we don't have to read the entire table. But after expanding $r$, there is a high chance that the user goes further and drills down on one of the sub-rules $r^{\prime}$ of $r$. We may not be able to use \textbf{Find} or \textbf{Combine} on $r^{\prime}$ with the existing samples. So while the user is busy reading the current rule-list obtained from drilling down on $r$, we can start running the algorithm from Section~\ref{sec:sampling_algorithms} in the background, and then making a pass through the table to create a new samples. That way, when the user expands the next rule $r^{\prime}$, there will be a high chance of a sample being pre-fetched for $r^{\prime}$, increasing the chance that we can use \textbf{Find} or \textbf{Combine} on $r^{\prime}$ and reducing our response time.
In addition, while we are making the pass in the background, we can find the exact counts for currently displayed rules (which only have estimated counts shown), and update them when our pass is complete.
}
