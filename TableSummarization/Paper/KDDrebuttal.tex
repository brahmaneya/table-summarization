\documentclass{article}
\date{\today}



\begin{document}

\title{Smart Drill-Down (KDD Rebuttal)}
\author{Manas Joglekar, Hector Garcia-Molina, Aditya Parameswaran}
\maketitle

We would like to thank the reviewers for their insightful and incredibly useful comments. The primary comment made by every reviewer was that we had missed several papers related to our work. We are outsiders to the KDD community, and were not very familiar with previous work in pattern mining. Indeed, our paper considers a type of pattern mining, and should have cited the papers pointed out by the reviewers. However, there are significant differences with existing pattern mining work, which we believe make our paper interesting. We describe these differences below. We plan to significantly augment our related work section, describing the differences with the referenced papers and other pattern mining work.

There are three primary ways in which existing work on pattern mining differs from our work:

1) Interactiveness: Smart drill-down allows the user to direct the data exploration according to his interests. This means that in each step, the number of rules displayed to the user should be small enough to be readable in a short amount of time, and the next set of rules to be displayed should depend on what part of the table the user expresses interest in. In addition, the response time of the system needs to be small (<10 seconds) to prevent the user's flow of thought from being broken. In contrast, many of the mentioned papers (e.g. `The Chosen few', `Constraint based Pattern Mining') display all output patterns in one go, which would take a lot of processing time and potentially display unneeded information to the user. Some, such as `Krimp', `Summarizing Itemset Patterns' display a smaller number of patterns, but are still not interactive. Note that our need for interactivity causes us to implement a smart memory manager that can use limited memory effectively while preparing for future requests.

2) Relational Data: Smart drill-down is used for summarizing data from a relational table, as opposed to a set of transactions. Different columns in a table can be of differing importance to a user, and smart drill-down allows a user to focus on expanding certain columns, while ignoring others. In a transaction based database, it is much harder to express extra interest in certain `types' of items.

3) Tunability: An important attribute of our work is that we allow the user to specify the kind of rules he/she is interested in by specifying any monotone weighting function. While this allows for a very wide variety of interestingness measures, the scoring function is restricted enough that it is submodular on the rule-set, allowing us to obtain an `approximate optimality guarantee'. Thus we strike a balance between tunability and optimizability. This is in contrast to related papers with a fully general scoring function (`Diverse subgroup set discovery'), forcing the use of an algorithm that is either heuristic with no optimality guarantees, or very time consuming. Some other papers (`MIME', `One click mining', `Finding Robust Itemsets Under Subsampling', `A framework for mining interesting pattern sets') are not tunable enough, and only provide a fixed set of interestingess parameters.

Further, the paper on `Intelligent roll-ups' is about roll-ups as opposed to drill down. It assumes that the user is already at a detailed level of the table, has found an anomaly, and wants to `zoom out' to the highest level where the anomaly still exists.

Based on Reviewer 2's suggestion, we will add a more detailed comparison between our contributions and existing work in Section 1 itself. Reviewer 2 also pointed out that we spent too much space on somewhat simple explanations;
this is again because we are outsiders to KDD and felt the need to explain things in detail. We'd be happy to move some of the more technical aspects and proofs from the technical report back to the paper once we shorten these explanations.

Reviewer 4 mentions that our experiments do not sufficiently demonstrate scalability. In fact, the performance of our rule finding algorithm depends only on the sample size it runs on, so once our system creates a sample (in time linear in table size), it should have the same processing time for different sized datasets.

Reviewer 5 suggests we use a multivariate discretizer to preserve interactions for continuous valued data. We thank the reviewer for this suggestion, and will incorporate this into our system.

Reviewer 6 correctly points out that it is the processing requirements of the apriori algorithm that make the sampling procedure necessary for the 2.5M tuple dataset. The rule finding algorithm makes several passes over the dataset, and would be very slow if it had to make many passes over so many tuples. Here, sampling helps with speed, but can be done away with otherwise. On the other hand, users might want to explore even bigger datasets, containing billions of tuples, where the dataset doesn't fit in main memory at all; here, sampling is not just a nice-to-have, it is a must-have.

\end{document}

